---
title: "The best of both worlds: learning geometry-based 6D object pose estimation"
collection: publications
permalink: /publication/2017-11-15-CVPR-pose
excerpt: 'We address the task of estimating the 6D pose of known rigid objects, from RGB and RGB-D input images, in scenarios where the objects are heavily occluded. Our main contribution is a new modular processing pipeline. The first module localizes all known objects in the image via an existing instance segmentation network. The next module densely regresses the object surface positions in its local coordinate system, using an encoder-decoder network. The third module is purely a geometry-based algorithm to output the final 6D object poses. While the first two modules are learned from data, and the last one not, we believe that this is the best of both worlds: geometry-based and learning-based algorithms for object 6D pose estimation. This is validated by achieving state-of-the-art results for RGB input and a slight improvement over state-of-the-art for RGB-D input. However, in contrast to previous work, we achieve these results with the same pipeline for RGB and RGB-D input. Furthermore, to obtain these results, we give a second contribution of a new 3D occlusion-aware and object-centric data augmentation procedure.
[[pdf]](http://kpertsch.github.io/files/pose_CVPR18.pdf), [[arXiv]](https://arxiv.org/abs/1712.01924)'
date: 2017-11-15
venue: '[submitted] Conference on Computer Vision and Pattern Recognition (CVPR) 2018'
paperurl: ''
citation: 'O. H. Jaffari*, S. K. Mustikovela*, K. Pertsch, E. Brachmann, C. Rother. (2017). &quot;The best of both worlds: learning geometry-based 6D object pose estimation.&quot; <i>arXiv:1712.01924</i>.'
---
We address the task of estimating the 6D pose of known rigid objects, from RGB and RGB-D input images, in scenarios where the objects are heavily occluded. Our main contribution is a new modular processing pipeline. The first module localizes all known objects in the image via an existing instance segmentation network. The next module densely regresses the object surface positions in its local coordinate system, using an encoder-decoder network. The third module is purely a geometry-based algorithm to output the final 6D object poses. While the first two modules are learned from data, and the last one not, we believe that this is the best of both worlds: geometry-based and learning-based algorithms for object 6D pose estimation. This is validated by achieving state-of-the-art results for RGB input and a slight improvement over state-of-the-art for RGB-D input. However, in contrast to previous work, we achieve these results with the same pipeline for RGB and RGB-D input. Furthermore, to obtain these results, we give a second contribution of a new 3D occlusion-aware and object-centric data augmentation procedure.

[[pdf]](http://kpertsch.github.io/files/pose_CVPR18.pdf), [[arXiv]](https://arxiv.org/abs/1712.01924)

Recommended citation: O. H. Jaffari*, S. K. Mustikovela*, K. Pertsch, E. Brachmann, C. Rother. (2017). "The best of both worlds: learning geometry-based 6D object pose estimation." <i>arXiv:1712.01924</i>.